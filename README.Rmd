---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r knit_config, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Automating R Simulation Studies

<!-- badges: start -->

<!-- badges: end -->

The goal of this repository is to provide [`R`](https://www.r-project.org/) users an example of how to **automate simulation studies on high-performance computing platforms (a.k.a. the cluster)**. The pipeline was initially written for [`Slurm`](https://slurm.schedmd.com/documentation.html) scheduling system, but can be easily modified for other systems.

The main idea of this pipeline is to use R to compose jobs via system call, where each job corresponds to a batch of replications under the same simulation setting. These replications are implemented via the Slurm *job array* feature using the flag [`--array`](https://slurm.schedmd.com/job_array.html).

## Toy Example: Central Limit Theorem

We use a simulation study of the central limit theorem (CLT) to demonstrate the pipeline. In this example, we simulate random samples $(X_1, \dots, X_n)$ of size $n \in {5, 10, 50, 100, 500, 1000, 5000, 10000}$ from independent and identical Poisson distribution with mean $\lambda = 3$, and calculate the sample mean $\bar X$ of the $n$ random sample. This process is repeated for 100000 times to generate a heuristic distribution of $\bar X$. We hypothesize this heuristic distribution should closely match to a normal distribution of mean 3 and variance 3, particularly when $n$ grows larger. To examine our hypothesis, we record the mean, median, variance of the heuristic distribution. This concludes as one replication, and we have $n_{\text{it}} = 1000$ replications for each setting of $n$.

To put the simulation study in the context of the pipeline, we have

-   one simulation parameter: the size of random samples $n$  
-   the data generating process: 1000 samples of $(X_1, \dots, X_n)$ where $X_i \sim \text{Poisson}(\lambda=3)$ i.i.d. for $i = 1, \dots, n$  
-   the model and its output: the heuristic distribution of $\bar X$ and its mean, median, variance
-   the number of replications for each simulation setting: $n_{\text{it}} =1000$

### Getting Started

1.  Copy three code files (including `start_sim.R`, `slurm_job_config.job`, `main.R`) in the folder `Code-copy_me` to your working directory on the cluster.

2.  Replace the code section [TODO: insert permanent link here] in the `main.R` file with you simulation code

3.  Replace the directory paths with your preferred path

    -   [Global search](https://support.rstudio.com/hc/en-us/articles/200710523-Navigating-Code) the phrase `TODO: Replace path here` in the code files
    -   We recommend to use [absolute path instead of relative path](https://www.linux.com/training-tutorials/absolute-path-vs-relative-path-linuxunix/) in your files

4.  In the log-in node of the cluster, source the file `start_sim.R` in an R console or run `R CMD BATCH start_sim.R` in the command line within your working directory, i.e. the directory that contains the three code files

    -   You still need to load the R module before running the R script in your preferred way.

5.  Wait to see the simulation output in the designated storage folder/directory

    -   If there was something wrong with the simulation, go to your log folder/directory

## Techinical Explaination
[TODO: add flow chart here]


## Questions/Discussion Board
[TODO: add link to the repo issue page + template]

    
## Related Resources
### Simulation Strategies
-   Modulize your code
-   Test out your code before deployment on the cluster
-   Choose the correct partition
-   Raw Data Vs Simulation Results
-   Trade-offs: Change parameters of the jobs

### Other Tools
-   Use `Targets`

### Design Your Simulation Study
- Add Morris, White, Crowther (2017) Stat in Med Paper
